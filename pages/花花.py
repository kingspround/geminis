import google.generativeai as genai
import streamlit as st
from dotenv import load_dotenv
import os
from PIL import Image
import numpy as np
from io import BytesIO
from io import StringIO
import random
import pickle

# API Key è®¾ç½®
st.session_state.key = "AIzaSyDPFZ7gRba9mhKTqbXA_Y7fhAxS8IEu0bY"  # **è¯·å‹¿å°†æ‚¨çš„API Key æ³„éœ²åœ¨å…¬å¼€åœºåˆ**
if "key" not in st.session_state:
    st.session_state.key = None
if not st.session_state.key:
    st.info("Please add your key to continue.")
    st.stop()

genai.configure(api_key=st.session_state.key)

# æ¨¡å‹è®¾ç½®
generation_config = {
    "temperature": 1,
    "top_p": 0,
    "top_k": 0,
    "max_output_tokens": 10000,
}
safety_settings = [
    {
        "category": "HARM_CATEGORY_HARASSMENT",
        "threshold": "BLOCK_NONE",
    },
    {
        "category": "HARM_CATEGORY_HATE_SPEECH",
        "threshold": "BLOCK_NONE",
    },
    {
        "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
        "threshold": "BLOCK_NONE",
    },
    {
        "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
        "threshold": "BLOCK_NONE",
    },
]
model = genai.GenerativeModel(model_name="gemini-1.5-pro-latest", generation_config=generation_config,
                            safety_settings=safety_settings)
# Vision Model
model_v = genai.GenerativeModel(model_name='gemini-pro-vision', generation_config=generation_config)


# LLM
def generate_token():
    """ç”Ÿæˆä¸€ä¸ª 10 ä½åˆ° 20 ä½çš„éšæœº token"""
    token_length = random.randint(10, 20)
    characters = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'
    token = ''.join(random.choice(characters) for i in range(token_length))
    return token


def getAnswer(prompt, token, image):
    his_messages = []
    his_messages.append(
        {"role": "model", "parts": [{"text": f"ä½ çš„éšæœºtokenæ˜¯ï¼š{token}"}]}
    )
    # åªä¿ç•™ç”¨æˆ·è¾“å…¥çš„æœ€åä¸€æ¡æ¶ˆæ¯
    for msg in st.session_state.messages[-1:]:
        if msg["role"] == "user":
            his_messages.append({"role": "user", "parts": [{"text": msg["content"]}]})
    if image is not None:
        # å°†å›¾ç‰‡è½¬æ¢ä¸ºå­—èŠ‚æµ
        img_bytes = BytesIO()
        image.save(img_bytes, format='JPEG')
        img_bytes.seek(0)
        prompt_v = ""
        for msg in st.session_state.messages[-1:]:
            prompt_v += f'''{msg["role"]}:{msg["content"]}'''
        response = model_v.generate_content([prompt_v, img_bytes], stream=True)  # å°†å›¾ç‰‡å­—èŠ‚æµä¼ é€’ç»™æ¨¡å‹
    else:
        response = model.generate_content(contents=his_messages, stream=True)
    full_response = ""
    for chunk in response:
        full_response += chunk.text
        yield chunk.text
    #  æ›´æ–°æœ€åä¸€æ¡å›å¤
    if st.session_state.last_response:
        st.session_state.last_response[-1] = full_response


def save_history():
    """å°†èŠå¤©è®°å½•ä¿å­˜åˆ° logs æ–‡ä»¶å¤¹çš„ chat_log.pkl æ–‡ä»¶"""
    os.makedirs("logs", exist_ok=True)
    # è·å–å½“å‰æ–‡ä»¶å
    current_filename = os.path.basename(__file__).split('.')[0]
    # ä¿å­˜èŠå¤©è®°å½•åˆ° logs æ–‡ä»¶å¤¹
    filename = os.path.join("logs", f"{current_filename}_chat_log.pkl")
    with open(filename, "wb") as f:
        pickle.dump(st.session_state.messages, f)


def load_history():
    """ä» logs æ–‡ä»¶å¤¹åŠ è½½èŠå¤©è®°å½•"""
    files = [f for f in os.listdir("logs") if f.endswith(".pkl")]
    if files:
        selected_file = st.selectbox("é€‰æ‹©è¦åŠ è½½çš„è®°å½•æ–‡ä»¶", files)
        filename = os.path.join("logs", selected_file)
        with open(filename, "rb") as f:
            st.session_state.messages = pickle.load(f)
        st.success(f"èŠå¤©è®°å½•å·²åŠ è½½")
    else:
        st.warning("logs æ–‡ä»¶å¤¹ä¸­æ²¡æœ‰è®°å½•æ–‡ä»¶")


def clear_history():
    """æ¸…é™¤å½“å‰èŠå¤©è®°å½•"""
    st.session_state.messages = []
    st.session_state.last_response = []  # æ¸…é™¤ last_response åˆ—è¡¨
    st.session_state.page_index = 0  # é‡ç½®é¡µé¢ç´¢å¼•
    st.success("èŠå¤©è®°å½•å·²æ¸…é™¤")


def increase_page_index():
    """å¢åŠ é¡µé¢ç´¢å¼•"""
    st.session_state.page_index += 1
    # é‡æ–°æ˜¾ç¤ºå½“å‰é¡µé¢çš„ AI å›å¤
    if st.session_state.page_index >= 0 and st.session_state.page_index < len(st.session_state.last_response):
        with st.chat_message("assistant"):
            st.markdown(st.session_state.last_response[st.session_state.page_index])


def decrease_page_index():
    """å‡å°‘é¡µé¢ç´¢å¼•"""
    st.session_state.page_index = max(0, st.session_state.page_index - 1)
    # é‡æ–°æ˜¾ç¤ºå½“å‰é¡µé¢çš„ AI å›å¤
    if st.session_state.page_index >= 0 and st.session_state.page_index < len(st.session_state.last_response):
        with st.chat_message("assistant"):
            st.markdown(st.session_state.last_response[st.session_state.page_index])


def next_page_index():
    """è·³è½¬åˆ°ä¸‹ä¸€é¡µ"""
    st.session_state.page_index = min(len(st.session_state.last_response) - 1, st.session_state.page_index + 1)
    # é‡æ–°æ˜¾ç¤ºå½“å‰é¡µé¢çš„ AI å›å¤
    if st.session_state.page_index >= 0 and st.session_state.page_index < len(st.session_state.last_response):
        with st.chat_message("assistant"):
            st.markdown(st.session_state.last_response[st.session_state.page_index])


def reoutput_last_response():
    """é‡æ–°è¾“å‡ºæœ€åä¸€æ¡å›å¤"""
    if st.session_state.last_response:
        st.session_state.page_index = len(st.session_state.last_response) - 1
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            full_response = ""
            for chunk in getAnswer(st.session_state.messages[-1]["content"], st.session_state.messages[-1]["token"],
                                    st.session_state.img):
                full_response += chunk
                message_placeholder.markdown(full_response + "â–Œ")
            message_placeholder.markdown(full_response)


def generate_new_response():
    """ç”Ÿæˆæ–°çš„å›å¤å¹¶æ˜¾ç¤º"""
    if st.session_state.messages:
        # è·å–æœ€åä¸€ä¸ªç”¨æˆ·çš„æç¤ºå’Œtoken
        last_user_prompt = st.session_state.messages[-1]["content"]
        last_user_token = st.session_state.messages[-1]["token"]
        # ç”Ÿæˆæ–°å›å¤
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            full_response = ""
            for chunk in getAnswer(last_user_prompt, last_user_token, st.session_state.img):
                full_response += chunk
                message_placeholder.markdown(full_response + "â–Œ")
            message_placeholder.markdown(full_response)
        # æ›´æ–° last_response å’Œ page_index
        st.session_state.last_response.append(full_response)
        st.session_state.page_index = len(st.session_state.last_response) - 1
        
        # ç°åœ¨ï¼Œåœ¨æ›´æ–° last_response åï¼Œæˆ‘ä»¬éœ€è¦æ›´æ–° page_indexï¼Œä»¥ç¡®ä¿ç¼–è¾‘åŠŸèƒ½å¯ä»¥å®šä½åˆ°æœ€æ–°çš„ AI å›å¤
        st.session_state.page_index += 1

# === æ–‡ä»¶å¤„ç† ===
# è·å–æ–‡ä»¶åï¼Œå¹¶ç”Ÿæˆå¯¹åº”çš„æ–‡ä»¶å
filename = os.path.splitext(os.path.basename(__file__))[0] + ".pkl"
log_file = os.path.join(os.path.dirname(__file__), filename)

# æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨å°±åˆ›å»ºç©ºæ–‡ä»¶
if not os.path.exists(log_file):
    with open(log_file, "wb") as f:
        pass

# åŠ è½½å†å²è®°å½•ï¼ˆåªæ‰§è¡Œä¸€æ¬¡ï¼‰
if "messages" not in st.session_state:
    try:
        with open(log_file, "rb") as f:
            st.session_state.messages = pickle.load(f)
    except FileNotFoundError:
        st.session_state.messages = []
    except EOFError:
        st.warning(f"è¯»å–å†å²è®°å½•å¤±è´¥ï¼šæ–‡ä»¶å¯èƒ½æŸåã€‚")
        st.session_state.messages = []

if "messages" not in st.session_state:
    st.session_state.messages = []
if "img" not in st.session_state:
    st.session_state.img = None
if "last_response" not in st.session_state:
    st.session_state.last_response = [""]  # åˆå§‹åŒ–æ—¶æ·»åŠ é»˜è®¤å€¼
if "page_index" not in st.session_state:
    st.session_state.page_index = 0

# ===  èŠå¤©æ˜¾ç¤ºå’Œç¼–è¾‘  ===
# ç”¨äºæ ‡è®°å½“å‰æ­£åœ¨ç¼–è¾‘çš„æ¶ˆæ¯ç´¢å¼•
if "editing_index" not in st.session_state:
    st.session_state.editing_index = None

# ä¾§è¾¹æ 
st.sidebar.title("æ§åˆ¶é¢æ¿")
st.sidebar.button("è¯»å–å†å²è®°å½•", on_click=load_history)
st.sidebar.button("æ¸…é™¤å†å²è®°å½•", on_click=clear_history)
st.sidebar.button("é‡ç½®ä¸Šä¸€ä¸ªè¾“å‡º", on_click=lambda: st.session_state.messages.pop(-1))
# å›¾ç‰‡ä¸Šä¼ 
uploaded_file = st.sidebar.file_uploader("ä¸Šä¼ å›¾ç‰‡", type=['png', 'jpg', 'jpeg', 'gif'])
if uploaded_file is not None:
    # To read file as bytes:
    bytes_data = uploaded_file.getvalue()
    bytes_io = BytesIO(bytes_data)
    img = Image.open(bytes_io)
    # å°†å›¾ç‰‡è½¬æ¢ä¸º JPEG æ ¼å¼
    img = img.convert('RGB')
    st.session_state.img = img  # ä¿å­˜åˆ° st.session_state.img
    st.sidebar.image(bytes_io, width=150)  # åœ¨ä¾§è¾¹æ æ˜¾ç¤ºå›¾ç‰‡

# å¾ªç¯æ˜¾ç¤ºèŠå¤©æ¶ˆæ¯
for i, message in enumerate(st.session_state.messages):
    col1, col2 = st.columns([9, 1])  # è°ƒæ•´åˆ—å®½ï¼Œä¸ºæŒ‰é’®é¢„ç•™æ›´å¤šç©ºé—´
    with col1:
        with st.chat_message(message["role"]):
            st.write(message["content"], key=f"message_{i}")

    # ===  åœ¨å¾ªç¯å†…éƒ¨æ·»åŠ æŒ‰é’®å’Œç¼–è¾‘é€»è¾‘ ===
    # ä½¿ç”¨ st.session_state.page_index æ¥åˆ¤æ–­æ˜¯å¦ä¸ºå½“å‰é¡µé¢
    if i == st.session_state.page_index:  
        with col2:
            #  ç¼–è¾‘æŒ‰é’®
            if st.button("âœï¸", key=f"edit_button_{i}"):
                st.session_state.editing_index = i

            col3, col4, col5, col6, col7 = st.columns(5)

            with col3:
                st.button("ğŸ”„", key=f"reoutput_{i}", on_click=reoutput_last_response)

            with col4:
                st.button("ğŸ’¬", key=f"generate_{i}", on_click=generate_new_response)

            with col5:
                st.button("âª", key=f"decrease_{i}", on_click=decrease_page_index,
                           disabled=st.session_state.page_index == 0)

            with col6:
                st.button("â©", key=f"next_{i}", on_click=next_page_index,
                           disabled=st.session_state.page_index == len(st.session_state.last_response) - 1)

    # å¦‚æœå½“å‰æ¶ˆæ¯æ­£åœ¨ç¼–è¾‘ï¼Œæ˜¾ç¤ºæ–‡æœ¬æ¡†
    if st.session_state.editing_index == i:
        with st.chat_message(message["role"]):
            new_content = st.text_area(
                "ç¼–è¾‘æ¶ˆæ¯:",
                value=message["content"],
                key=f"edit_text_{i}"
            )
            if st.button("ä¿å­˜", key=f"save_button_{i}"):
                # æ›´æ–°æ¶ˆæ¯å†…å®¹
                st.session_state.messages[i]["content"] = new_content
                # ä¿å­˜åˆ°æ–‡ä»¶
                with open(log_file, "wb") as f:
                    pickle.dump(st.session_state.messages, f)
                # é‡ç½®ç¼–è¾‘çŠ¶æ€
                st.session_state.editing_index = None
                # åˆ·æ–°é¡µé¢ï¼Œé‡æ–°åŠ è½½èŠå¤©è®°å½•
                st.experimental_rerun()
# æ˜¾ç¤ºå½“å‰é¡µé¢çš„ AI å›å¤
if st.session_state.page_index >= 0 and st.session_state.page_index < len(st.session_state.last_response):
    with st.chat_message("assistant"):
        st.markdown(st.session_state.last_response[st.session_state.page_index])

# æ˜¾ç¤ºé¡µç 
if len(st.session_state.last_response) > 1:
    st.write(f"ç¬¬ {st.session_state.page_index + 1} é¡µ / å…± {len(st.session_state.last_response)} é¡µ")


if prompt := st.chat_input("Enter your message:"):
    token = generate_token()
    st.session_state.messages.append({"role": "user", "content": prompt, "token": token})
    with st.chat_message("user"):
        st.markdown(prompt)
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        # åœ¨è·å–å›å¤æ—¶ä¼ å…¥token
        for chunk in getAnswer(prompt, token, st.session_state.img):
            full_response += chunk
            message_placeholder.markdown(full_response + "â–Œ")
        message_placeholder.markdown(full_response)
    # æ›´æ–° last_response å’Œ page_index
    st.session_state.last_response.append(full_response)
    st.session_state.page_index = len(st.session_state.last_response) - 1
# è‡ªåŠ¨ä¿å­˜èŠå¤©è®°å½•
save_history()
