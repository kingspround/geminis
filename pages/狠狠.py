import openai
import streamlit as st
import pickle
import os

# è®¾ç½® OpenAI API å¯†é’¥
openai.api_key = st.secrets["sk-zGzsKlEMKwMgpXPThLcEvOQ9fuDXG0J4oBqz-yepz1T3BlbkFJrGTEp7fUWyY0RU54RfRdLqhfyui7H_gWe76PDVX2UA"] 

# åˆå§‹åŒ–èŠå¤©å†å²è®°å½•
if "messages" not in st.session_state:
    st.session_state.messages = []

# --- å‡½æ•°å®šä¹‰ ---
def generate_response(messages):
    """ä½¿ç”¨ OpenAI API ç”Ÿæˆå›å¤"""
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",  # ä½¿ç”¨ ChatGPT æ¨¡å‹
        messages=messages,
    )
    return response.choices[0].message.content

# --- Streamlit åº”ç”¨ç¨‹åº ---
st.title("ğŸ¤– ChatGPT èŠå¤©æœºå™¨äºº")

# --- ä¾§è¾¹æ  ---
st.sidebar.title("æ“ä½œ")

# åŠ è½½å†å²è®°å½•
def load_history(log_file):
    try:
        with open(log_file, "rb") as f:
            st.session_state.messages = pickle.load(f)
        st.experimental_rerun()
    except FileNotFoundError:
        st.warning(f"{log_file} ä¸å­˜åœ¨ã€‚")
    except EOFError:
        st.warning(f"è¯»å–å†å²è®°å½•å¤±è´¥ï¼šæ–‡ä»¶å¯èƒ½æŸåã€‚")

# æ¸…é™¤å†å²è®°å½•
def clear_history(log_file):
    st.session_state.messages = []
    try:
        os.remove(log_file)
        st.success(f"æˆåŠŸæ¸…é™¤ {log_file} çš„å†å²è®°å½•ï¼")
    except FileNotFoundError:
        st.warning(f"{log_file} ä¸å­˜åœ¨ã€‚")

# è·å–æ–‡ä»¶å
filename = "chat_history.pkl"
log_file = os.path.join(os.path.dirname(__file__), filename)

if st.sidebar.button("è¯»å–å†å²è®°å½•"):
    load_history(log_file)

if st.sidebar.button("æ¸…é™¤å†å²è®°å½•"):
    clear_history(log_file)

# --- ä¸»èŠå¤©ç•Œé¢ ---
# æ˜¾ç¤ºèŠå¤©è®°å½•
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ç”¨æˆ·è¾“å…¥
if prompt := st.chat_input("è¾“å…¥ä½ çš„æ¶ˆæ¯:"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # ç”Ÿæˆå›å¤
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        for chunk in generate_response(st.session_state.messages).split():
            full_response += chunk + " "
            message_placeholder.markdown(full_response + "â–Œ")
        message_placeholder.markdown(full_response)
    st.session_state.messages.append({"role": "assistant", "content": full_response})

# ä¿å­˜èŠå¤©è®°å½•
with open(log_file, "wb") as f:
    pickle.dump(st.session_state.messages, f)
