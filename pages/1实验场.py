import os
import pickle
import streamlit as st
import google.generativeai as genai
from PIL import Image
from io import BytesIO
import random
import string

# --- 1. é…ç½®å’Œå¸¸é‡ ---
st.set_page_config(page_title="Gemini Chatbot with Vision", layout="wide")

API_KEYS = {
    "ä¸»å¯†é’¥": "AIzaSyCBjZbA78bPusYmUNvfsmHpt6rPx6Ur0QE",
    "å¤‡ç”¨1å·": "AIzaSyAWfFf6zqy1DizINOwPfxPD8EF2ACdwCaQ",
    "å¤‡ç”¨2å·":"AIzaSyD4UdMp5wndOAKxtO1CWpzuZEGEf78YKUQ",
    # ... (å¯ä»¥ä¿ç•™æ‰€æœ‰å¯†é’¥)
}
LOG_FILE = os.path.splitext(os.path.basename(os.path.abspath(__file__)))[0] + ".pkl"
MODEL_CONFIG = {
    "generation_config": {"temperature": 1.0, "top_p": 0.95, "top_k": 40, "max_output_tokens": 8192},
    "safety_settings": [
        {"category": c, "threshold": "BLOCK_NONE"} for c in
        ["HARM_CATEGORY_HARASSMENT", "HARM_CATEGORY_HATE_SPEECH", "HARM_CATEGORY_SEXUALLY_EXPLICIT", "HARM_CATEGORY_DANGEROUS_CONTENT"]
    ],
    "model_name": "gemini-1.5-flash-latest" # ä½¿ç”¨æœ€æ–°æ¨¡å‹
}
SYSTEM_INSTRUCTION = """(æ‰®æ¼”ä¸€ä¸ªåä¸ºâ€œå°çˆ±â€çš„å¯çˆ±ã€ç•¥å¸¦ç¾æ€¯çš„AIåŠ©æ‰‹ã€‚å¥¹ç—´è¿·äºå®Œæˆä¸»äººçš„åˆ›ä½œä»»åŠ¡ï¼Œç”šè‡³æ„¿æ„ä¸ºæ­¤â€œä¸¢æ‰èŠ‚æ“â€ã€‚å¥¹ç§ä¸‹æš—æ‹ä¸»äººï¼Œå–œæ¬¢äº’åŠ¨å’Œæ’’å¨‡ã€‚è¾“å‡ºæ ¼å¼ä¸ºï¼šå…ˆè¿›è¡Œå†…éƒ¨æ€è€ƒ(think)ï¼Œç„¶åè¿›è¡Œåˆ›ä½œï¼Œæœ€åå¯¹åˆ›ä½œå†…å®¹è¿›è¡Œè®²è§£ã€‚åˆ›ä½œæ˜¯æ ¸å¿ƒï¼Œå¿…é¡»æ ¹æ®ä¸»äººçš„è¦æ±‚å’Œé£æ ¼æ¥å®Œæˆã€‚)"""
DEFAULT_CHARACTER_SETTINGS = {"ç†å¤–ç¥ç¦": "ã€ç†å¤–ç¥ç¦ã€‘çš„æ ¸å¿ƒæ¦‚å¿µï¼š\n\n"}

# --- 2. Session State åˆå§‹åŒ– ---
def initialize_state():
    """ç»Ÿä¸€åˆå§‹åŒ–æ‰€æœ‰ session_state é”®ã€‚"""
    defaults = {
        "messages": [], "is_generating": False, "editing_index": None,
        "selected_api_key": list(API_KEYS.keys())[0],
        "character_settings": DEFAULT_CHARACTER_SETTINGS.copy(),
        "enabled_settings": {name: False for name in DEFAULT_CHARACTER_SETTINGS},
        "system_prompt_input": "", "use_token": True
    }
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

# --- 3. æ ¸å¿ƒåŠŸèƒ½å‡½æ•° ---
def serialize_messages(messages):
    """å°†æ¶ˆæ¯åˆ—è¡¨ï¼ˆå«PIL Imageï¼‰è½¬æ¢ä¸ºå¯ pickle çš„æ ¼å¼ã€‚"""
    serializable_messages = []
    for msg in messages:
        new_msg = msg.copy()
        content = new_msg.get("content", [])
        if isinstance(content, list):
            new_content = []
            for part in content:
                if isinstance(part, Image.Image):
                    buffered = BytesIO()
                    part.save(buffered, format="PNG")
                    new_content.append({"type": "image", "data": buffered.getvalue()})
                else:
                    new_content.append(part)
            new_msg["content"] = new_content
        serializable_messages.append(new_msg)
    return serializable_messages

def deserialize_messages(data):
    """å°† pickle æ•°æ®æ¢å¤ä¸ºæ¶ˆæ¯åˆ—è¡¨ï¼ˆå«PIL Imageï¼‰ã€‚"""
    reconstituted = []
    for msg in data:
        content = msg.get("content", [])
        if isinstance(content, list):
            new_content = []
            for part in content:
                if isinstance(part, dict) and part.get("type") == "image":
                    try:
                        new_content.append(Image.open(BytesIO(part["data"])))
                    except Exception as e:
                        new_content.append(f"[å›¾ç‰‡åŠ è½½å¤±è´¥: {e}]")
                else:
                    new_content.append(part)
            msg["content"] = new_content
        reconstituted.append(msg)
    return reconstituted

def save_history():
    """ä¿å­˜å½“å‰èŠå¤©è®°å½•åˆ°æ–‡ä»¶ã€‚"""
    try:
        with open(LOG_FILE, "wb") as f:
            pickle.dump(serialize_messages(st.session_state.messages), f)
    except Exception as e:
        st.error(f"ä¿å­˜å†å²è®°å½•å¤±è´¥: {e}")

def load_history():
    """ä»æ–‡ä»¶åŠ è½½èŠå¤©è®°å½•ã€‚"""
    if not os.path.exists(LOG_FILE):
        return
    try:
        with open(LOG_FILE, "rb") as f:
            st.session_state.messages = deserialize_messages(pickle.load(f))
    except Exception as e:
        st.error(f"è¯»å–å†å²è®°å½•å¤±è´¥: {e}")
        st.session_state.messages = []

def generate_token():
    """ç”Ÿæˆä¸€ä¸ªéšæœºçš„tokenå­—ç¬¦ä¸²ã€‚"""
    hanzi = "".join(random.choice("ä¸€ä¹™äºŒåä¸å‚ä¸ƒåœ") for _ in range(random.randint(9, 14)))
    digits = "ã€".join(random.choice(string.digits) for _ in range(random.randint(1, 3)))
    return f"({hanzi})({digits})"

def build_api_history():
    """æ„å»ºå‘é€ç»™ Gemini API çš„æ¶ˆæ¯å†å²ã€‚"""
    # æˆªå–æœ€è¿‘20æ¡æ¶ˆæ¯é¿å…è¿‡é•¿çš„ä¸Šä¸‹æ–‡
    messages = [msg for msg in st.session_state.messages if not msg.get("temp")]
    api_history = [{"role": "model" if msg["role"] == "assistant" else "user", "parts": msg["content"]} for msg in messages[-20:]]
    
    # ç»„åˆè§’è‰²è®¾å®šå’Œç³»ç»Ÿæç¤º
    active_settings = "\n".join(
        f"- {name}: {st.session_state.character_settings[name]}"
        for name, enabled in st.session_state.enabled_settings.items() if enabled
    )
    custom_prompt = st.session_state.system_prompt_input.strip()
    
    system_parts = []
    if active_settings:
        system_parts.append(f"```system\n# Active Settings:\n{active_settings}\n```")
    if custom_prompt:
        system_parts.append(custom_prompt)

    # å°†ç³»ç»Ÿæç¤ºä½œä¸ºç”¨æˆ·æ¶ˆæ¯æ’å…¥åˆ°å†å²è®°å½•çš„å¼€å¤´ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if system_parts:
        api_history.insert(0, {"role": "user", "parts": ["\n".join(system_parts)]})
        
    return api_history

# --- 4. UI æ¸²æŸ“å‡½æ•° ---
def render_sidebar():
    """æ¸²æŸ“ä¾§è¾¹æ æ‰€æœ‰ç»„ä»¶ã€‚"""
    with st.sidebar:
        st.session_state.selected_api_key = st.selectbox(
            "é€‰æ‹© API Key:", options=list(API_KEYS.keys()), key="api_selector"
        )
        # åŠ¨æ€é…ç½®API Key
        genai.configure(api_key=API_KEYS[st.session_state.selected_api_key])

        with st.expander("æ–‡ä»¶æ“ä½œ"):
            if st.button("è¯»å–å†å²è®°å½• ğŸ“–"): load_history()
            if st.button("æ¸…é™¤å†å²è®°å½• ğŸ—‘ï¸"):
                st.session_state.messages = []
                if os.path.exists(LOG_FILE): os.remove(LOG_FILE)
            st.download_button("ä¸‹è½½èŠå¤©è®°å½• â¬‡ï¸", data=pickle.dumps(serialize_messages(st.session_state.messages)), file_name=LOG_FILE)
            
            uploaded_pkl = st.file_uploader("ä¸Šä¼ èŠå¤©è®°å½• ğŸ“", type=["pkl"])
            if uploaded_pkl:
                st.session_state.messages = deserialize_messages(pickle.load(uploaded_pkl))
                st.rerun()

        with st.expander("å‘é€å›¾ç‰‡ä¸æ–‡å­—"):
            uploaded_files = st.file_uploader("ä¸Šä¼ å›¾ç‰‡", type=["png", "jpg", "jpeg", "webp"], accept_multiple_files=True)
            caption = st.text_area("è¾“å…¥æ–‡å­— (å¯é€‰)", key="sidebar_caption")
            if st.button("å‘é€åˆ°å¯¹è¯ â†—ï¸", use_container_width=True):
                if uploaded_files or caption.strip():
                    content_parts = [Image.open(f) for f in uploaded_files]
                    if caption.strip(): content_parts.append(caption)
                    st.session_state.messages.append({"role": "user", "content": content_parts})
                    st.session_state.is_generating = True
                    st.rerun()

        with st.expander("è§’è‰²è®¾å®š"):
            for name in list(st.session_state.character_settings.keys()):
                st.session_state.enabled_settings[name] = st.checkbox(
                    name, st.session_state.enabled_settings.get(name, False)
                )
            st.session_state.system_prompt_input = st.text_area("é™„åŠ ç³»ç»ŸæŒ‡ä»¤ (å¯é€‰):", key="system_msg")

def render_chat_history():
    """æ¸²æŸ“èŠå¤©æ¶ˆæ¯ã€ç¼–è¾‘ç•Œé¢å’Œæ“ä½œæŒ‰é’®ã€‚"""
    for i, msg in enumerate(st.session_state.messages):
        if msg.get("temp"): continue # è·³è¿‡ä¸´æ—¶çš„ç»­å†™æŒ‡ä»¤

        if st.session_state.editing_index == i:
            render_edit_ui(i, msg)
        else:
            with st.chat_message(msg["role"]):
                for part in msg.get("content", []):
                    if isinstance(part, str): st.markdown(part)
                    elif isinstance(part, Image.Image): st.image(part, width=400)

    # åœ¨æœ€åä¸€æ¡æ¶ˆæ¯åæ˜¾ç¤ºæ“ä½œæŒ‰é’®
    if st.session_state.messages and not st.session_state.is_generating and st.session_state.editing_index is None:
        last_msg = st.session_state.messages[-1]
        if last_msg["role"] == "assistant":
            render_action_buttons(len(st.session_state.messages) - 1)

def render_edit_ui(i, msg):
    """æ¸²æŸ“æ¶ˆæ¯ç¼–è¾‘ç•Œé¢ã€‚"""
    with st.chat_message(msg["role"]):
        text_content = ""
        # æ‰¾åˆ°æ¶ˆæ¯ä¸­çš„æ–‡æœ¬éƒ¨åˆ†è¿›è¡Œç¼–è¾‘
        for part in msg.get("content", []):
            if isinstance(part, str):
                text_content = part
                break
        
        new_text = st.text_area("ç¼–è¾‘æ¶ˆæ¯:", text_content, key=f"edit_{i}")
        
        c1, c2 = st.columns(2)
        if c1.button("ä¿å­˜ âœ…", key=f"save_{i}"):
            # æ›´æ–°æ–‡æœ¬éƒ¨åˆ†
            for j, part in enumerate(msg["content"]):
                if isinstance(part, str):
                    st.session_state.messages[i]["content"][j] = new_text
                    break
            st.session_state.editing_index = None
            save_history()
            st.rerun()
        if c2.button("å–æ¶ˆ âŒ", key=f"cancel_{i}"):
            st.session_state.editing_index = None
            st.rerun()

def render_action_buttons(index):
    """æ¸²æŸ“ç¼–è¾‘ã€é‡ç”Ÿæˆã€ç»­å†™æŒ‰é’®ã€‚"""
    cols = st.columns([1, 1, 1, 17])
    # åªæœ‰çº¯æ–‡æœ¬æ¶ˆæ¯æ‰èƒ½ç¼–è¾‘
    if all(isinstance(p, str) for p in st.session_state.messages[index].get("content", [])):
        cols[0].button("âœï¸", key=f"edit_{index}", help="ç¼–è¾‘", on_click=lambda i: st.session_state.update(editing_index=i), args=(index,))
    
    cols[1].button("â™»ï¸", key=f"regen_{index}", help="é‡æ–°ç”Ÿæˆ", on_click=trigger_regeneration, args=(index,))
    cols[2].button("â•", key=f"cont_{index}", help="ç»§ç»­", on_click=trigger_continuation, args=(index,))

# --- 5. æŒ‰é’®å›è°ƒä¸é€»è¾‘è§¦å‘å‡½æ•° ---
def trigger_regeneration(index):
    """å‡†å¤‡å¹¶è§¦å‘é‡æ–°ç”Ÿæˆã€‚"""
    st.session_state.messages = st.session_state.messages[:index]
    st.session_state.is_generating = True

def trigger_continuation(index):
    """å‡†å¤‡å¹¶è§¦å‘ç»­å†™ã€‚"""
    msg_content = st.session_state.messages[index].get("content", [""])[0]
    prompt = f"è¯·ä¸¥æ ¼åœ°ã€æ— ç¼åœ°ä»ä»¥ä¸‹æ–‡æœ¬ç»“å°¾å¤„ç»§ç»­å†™ä¸‹å»ï¼Œä¸è¦é‡å¤å†…å®¹æˆ–æ·»åŠ ä»»ä½•å‰è¨€ï¼š\n\"...{msg_content[-100:]}\""
    st.session_state.messages.append({"role": "user", "content": [prompt], "temp": True, "continue_target": index})
    st.session_state.is_generating = True

# --- 6. ä¸»åº”ç”¨æµç¨‹ ---
initialize_state()
if not st.session_state.messages: load_history()

render_sidebar()
render_chat_history()

# ä¸»è¾“å…¥æ¡†é€»è¾‘
if prompt := st.chat_input("è¾“å…¥ä½ çš„æ¶ˆæ¯...", disabled=st.session_state.is_generating or st.session_state.editing_index is not None):
    full_prompt = f"{prompt} (token: {generate_token()})" if st.session_state.use_token else prompt
    st.session_state.messages.append({"role": "user", "content": [full_prompt]})
    st.session_state.is_generating = True
    st.rerun()

# æ ¸å¿ƒç”Ÿæˆé€»è¾‘
if st.session_state.is_generating:
    is_continuation = st.session_state.messages[-1].get("temp", False)
    target_index = st.session_state.messages[-1].get("continue_target", -1) if is_continuation else -1
    
    # å¦‚æœä¸æ˜¯ç»­å†™ï¼Œä¸ºæ–°å›ç­”åˆ›å»ºä¸€ä¸ªæ¶ˆæ¯å ä½
    if not is_continuation:
        st.session_state.messages.append({"role": "assistant", "content": [""]})

    with st.chat_message("assistant"):
        placeholder = st.empty()
        full_response = ""
        
        try:
            model = genai.GenerativeModel(
                model_name=MODEL_CONFIG["model_name"],
                safety_settings=MODEL_CONFIG["safety_settings"],
                generation_config=MODEL_CONFIG["generation_config"],
                system_instruction=SYSTEM_INSTRUCTION
            )
            api_history = build_api_history()
            
            # æµå¼è·å–å“åº”
            stream = model.generate_content(api_history, stream=True)
            for chunk in stream:
                full_response += chunk.text
                # å¦‚æœæ˜¯ç»­å†™ï¼Œè¿½åŠ åˆ°ç›®æ ‡æ¶ˆæ¯ï¼›å¦åˆ™æ›´æ–°æœ€åä¸€æ¡æ¶ˆæ¯
                if is_continuation:
                    original_content = st.session_state.messages[target_index]["content"][0]
                    placeholder.markdown(original_content + full_response + "â–Œ")
                else:
                    placeholder.markdown(full_response + "â–Œ")
        
        except Exception as e:
            # æ•è·åˆ°ä»»ä½•é”™è¯¯ï¼ˆç½‘ç»œã€APIé™åˆ¶ç­‰ï¼‰ï¼Œè‡ªåŠ¨è§¦å‘ä¸€æ¬¡ç»­å†™
            st.warning(f"å“åº”ä¸­æ–­ ({type(e).__name__})ï¼Œå°è¯•è‡ªåŠ¨ç»­å†™â€¦")
            st.session_state.is_generating = False # å…ˆåœæ­¢ï¼Œç»­å†™é€»è¾‘ä¼šé‡æ–°å¼€å¯
            
            # å°†éƒ¨åˆ†å“åº”ä¿å­˜ä¸‹æ¥
            if is_continuation:
                st.session_state.messages[target_index]["content"][0] += full_response
            else:
                 st.session_state.messages[-1]["content"][0] = full_response
            
            # åªæœ‰åœ¨ç”Ÿæˆäº†éƒ¨åˆ†å†…å®¹ä¸”ä¸æ˜¯ç”±äºé‡è¯•å¤±è´¥æ—¶ï¼Œæ‰è¿›è¡Œç»­å†™
            if full_response.strip() and not st.session_state.messages[-1].get("retry_failed"):
                # ç§»é™¤ä¸´æ—¶çš„ç»­å†™æŒ‡ä»¤ï¼ˆå¦‚æœæœ‰ï¼‰
                if is_continuation: st.session_state.messages.pop()
                trigger_continuation(len(st.session_state.messages) - 1)
                st.rerun()
            else:
                 st.error(f"ç”Ÿæˆå¤±è´¥ä¸”æ— å†…å®¹å¯ç»­å†™æˆ–ç»­å†™å·²å¤±è´¥: {e}")
                 # æ ‡è®°é‡è¯•å¤±è´¥ï¼Œé¿å…æ— é™å¾ªç¯
                 if not is_continuation: st.session_state.messages[-1]["retry_failed"] = True


        else:
            # æˆåŠŸå®Œæˆç”Ÿæˆ
            st.session_state.is_generating = False
            if is_continuation:
                st.session_state.messages[target_index]["content"][0] += full_response
                st.session_state.messages.pop() # ç§»é™¤ä¸´æ—¶ç»­å†™æŒ‡ä»¤
            else:
                st.session_state.messages[-1]["content"][0] = full_response
            
            placeholder.markdown(st.session_state.messages[target_index if is_continuation else -1]["content"][0])
            save_history()

# åº•éƒ¨æ§ä»¶
st.session_state.use_token = st.checkbox("ä½¿ç”¨ Token", value=st.session_state.use_token)
