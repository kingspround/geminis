import os
import google.generativeai as genai
import streamlit as st
import pickle
import random
import string
from io import BytesIO
from PIL import Image

# --- Streamlit Page Configuration ---
st.set_page_config(
    page_title="Gemini Chatbot with Vision",
    layout="wide"
)

# --- API å¯†é’¥è®¾ç½® (ä¿æŒä¸å˜) ---
API_KEYS = {
    "ä¸»å¯†é’¥": "AIzaSyCBjZbA78bPusYmUNvfsmHpt6rPx6Ur0QE",
    "å¤‡ç”¨1å·": "AIzaSyAWfFf6zqy1DizINOwPfxPD8EF2ACdwCaQ",
    "å¤‡ç”¨2å·":"AIzaSyD4UdMp5wndOAKxtO1CWpzuZEGEf78YKUQ",
    "å¤‡ç”¨3å·":"AIzaSyBVbA7tEyyy_ASp7l9P60qSh1xOM2CSMNw",
    "å¤‡ç”¨4å·":"AIzaSyDezEpxvtY1AKN6JACMU9XHte5sxATNcUs",
    "å¤‡ç”¨5å·":"AIzaSyBgyyy2kTTAdsLB53OCR2omEbj7zlx1mjw",
    "å¤‡ç”¨6å·":"AIzaSyDPFZ7gRba9mhKTqbXA_Y7fhAxS8IEu0bY",
    "å¤‡ç”¨7å·":"AIzaSyDdyhqcowl0ftcbK9pMObXzM7cIOQMtlmA",
    "å¤‡ç”¨8å·":"AIzaSyAA7Qs9Lzy4UxxIqCIQ4RknchiWQt_1hgI",
    "å¤‡ç”¨9å·":"AIzaSyCj_CCwQua1mfq3EjzqV6Up6NHsxtb9dy8",
    "å¤‡ç”¨10å·":"AIzaSyDOI2e-I1RdXBnk99jY2H00A3aymXREETA"
}

# --- åˆå§‹åŒ– Session State (å¢åŠ ä¸€ä¸ªçŠ¶æ€) ---
if "selected_api_key" not in st.session_state:
    st.session_state.selected_api_key = list(API_KEYS.keys())[0]
if "messages" not in st.session_state:
    st.session_state.messages = []
if 'editing' not in st.session_state:
    st.session_state.editing = False
if 'editable_index' not in st.session_state:
    st.session_state.editable_index = -1
if "is_generating" not in st.session_state:
    st.session_state.is_generating = False
if "use_token" not in st.session_state:
    st.session_state.use_token = True
# â˜…â˜…â˜… æ–°å¢çŠ¶æ€ï¼Œç”¨äºæ ‡è®°æ˜¯å¦ä¸ºâ€œç»§ç»­ç”Ÿæˆâ€ä»»åŠ¡ â˜…â˜…â˜…
if "is_continuing" not in st.session_state:
    st.session_state.is_continuing = False
# (å…¶ä»– session state åˆå§‹åŒ–ä¿æŒä¸å˜)
if 'character_settings' not in st.session_state:
    st.session_state.character_settings = {}
if 'enabled_settings' not in st.session_state:
    st.session_state.enabled_settings = {}
if "sidebar_caption" not in st.session_state:
    st.session_state.sidebar_caption = ""
if "clear_confirmation" not in st.session_state:
    st.session_state.clear_confirmation = False

# --- APIé…ç½®å’Œæ¨¡å‹å®šä¹‰ (ä¿æŒä¸å˜) ---
# ... (æ­¤éƒ¨åˆ†ä»£ç å®Œå…¨ä¸å˜)
genai.configure(api_key=API_KEYS[st.session_state.selected_api_key])
generation_config = {
  "temperature": 1.0, "top_p": 0.95, "top_k": 40, "max_output_tokens": 8192, "response_mime_type": "text/plain",
}
safety_settings = [
    {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
]
model = genai.GenerativeModel(
  model_name="gemini-1.5-flash-latest",
  generation_config=generation_config,
  safety_settings=safety_settings,
  system_instruction="""
{
 "<Writer_Activation>...</Writer_Activation>",
 "<System_Instruction>...</System_Instruction>",
 "æ‰®æ¼”è§’è‰²ï¼š...<core_principles>...</core_principles>\n\",",
}
""",
)
DEFAULT_CHARACTER_SETTINGS = { "ç†å¤–ç¥ç¦": """ã€ç†å¤–ç¥ç¦ã€‘çš„æ ¸å¿ƒæ¦‚å¿µï¼š\n\n""" }


# --- æ–‡ä»¶æ“ä½œä¸åŠŸèƒ½å‡½æ•° (åˆ é™¤äº† continue_message) ---
file = os.path.abspath(__file__)
filename = os.path.splitext(os.path.basename(file))[0] + ".pkl"
log_file = os.path.join(os.path.dirname(file), filename)
if not os.path.exists(log_file):
    with open(log_file, "wb") as f: pass
def _prepare_messages_for_save(messages):
    #... (æ­¤å‡½æ•°ä¸å˜)
    picklable_messages = []
    for msg in messages:
        new_msg = msg.copy(); new_content_list = []
        if isinstance(new_msg.get("content"), list):
            for part in new_msg["content"]:
                if isinstance(part, Image.Image):
                    buffered = BytesIO(); part.save(buffered, format="PNG")
                    new_content_list.append({"type": "image", "data": buffered.getvalue()})
                else: new_content_list.append(part)
            new_msg["content"] = new_content_list
        new_msg.pop("placeholder_widget", None)
        picklable_messages.append(new_msg)
    return picklable_messages
def _reconstitute_messages_after_load(messages):
    #... (æ­¤å‡½æ•°ä¸å˜)
    reconstituted_messages = []
    for msg in messages:
        new_msg = msg.copy(); content = new_msg.get("content"); new_content = []
        if isinstance(content, str): new_msg["content"] = [content]; reconstituted_messages.append(new_msg); continue
        if isinstance(content, list):
            for part in content:
                if isinstance(part, dict) and part.get("type") == "image":
                    try: new_content.append(Image.open(BytesIO(part["data"])))
                    except Exception as e: new_content.append(f"[å›¾ç‰‡åŠ è½½å¤±è´¥: {e}]")
                else: new_content.append(part)
            new_msg["content"] = new_content
        reconstituted_messages.append(new_msg)
    return reconstituted_messages
def generate_token():
    #... (æ­¤å‡½æ•°ä¸å˜)
    import random; import string; random.seed(); token_length = random.randint(10, 15)
    characters = "ä¸€ä¹™äºŒåä¸å‚ä¸ƒåœäººå…¥å…«"
    hanzi_token = "".join(random.choice(characters) for _ in range(token_length - 1))
    probability = random.random()
    if probability < 0.4: digit_count = 1
    elif probability < 0.7: digit_count = 2
    else: digit_count = 3
    digit_token = "ã€".join(random.choice(string.digits) for _ in range(digit_count))
    return f"({hanzi_token})({digit_token})"
def load_history(log_file):
    #... (æ­¤å‡½æ•°ä¸å˜)
    try:
        with open(log_file, "rb") as f:
            data = pickle.load(f)
            if isinstance(data, list): st.session_state.messages = _reconstitute_messages_after_load(data)
    except FileNotFoundError: pass
    except Exception as e: st.error(f"è¯»å–å†å²è®°å½•å¤±è´¥ï¼š{e}")
def clear_history(log_file):
    #... (æ­¤å‡½æ•°ä¸å˜)
    st.session_state.messages.clear()
    if os.path.exists(log_file): os.remove(log_file)
    st.success("å†å²è®°å½•å·²æ¸…é™¤ï¼")
def regenerate_message(index):
    #... (æ­¤å‡½æ•°ä¸å˜)
    if 0 <= index < len(st.session_state.messages) and st.session_state.messages[index]["role"] == "assistant":
        st.session_state.messages = st.session_state.messages[:index]
        st.session_state.is_generating = True
        st.experimental_rerun()

# â˜…â˜…â˜… æ–°çš„â€œç»§ç»­â€æŒ‰é’®å›è°ƒå‡½æ•°ï¼Œéå¸¸ç®€å• â˜…â˜…â˜…
def start_continuation():
    """æ ‡è®°ä¸€ä¸ªâ€œç»§ç»­â€ä»»åŠ¡ï¼Œå¹¶å¯åŠ¨ç”Ÿæˆæµç¨‹"""
    st.session_state.is_continuing = True
    st.session_state.is_generating = True

def send_from_sidebar_callback():
    #... (æ­¤å‡½æ•°ä¸å˜)
    uploaded_files = st.session_state.get("sidebar_uploader", [])
    caption = st.session_state.get("sidebar_caption", "").strip()
    if not uploaded_files and not caption:
        st.toast("è¯·è¾“å…¥æ–‡å­—æˆ–ä¸Šä¼ å›¾ç‰‡ï¼", icon="âš ï¸"); return
    content_parts = []
    if uploaded_files:
        for uploaded_file in uploaded_files:
            try: content_parts.append(Image.open(uploaded_file))
            except Exception as e: st.error(f"å¤„ç†å›¾ç‰‡ {uploaded_file.name} å¤±è´¥: {e}")
    if caption: content_parts.append(caption)
    if content_parts:
        st.session_state.messages.append({"role": "user", "content": content_parts})
        st.session_state.is_generating = True


# --- UI ä¾§è¾¹æ  (ä¿æŒä¸å˜) ---
with st.sidebar:
    st.session_state.selected_api_key = st.selectbox("é€‰æ‹© API Key:", options=list(API_KEYS.keys()), index=list(API_KEYS.keys()).index(st.session_state.selected_api_key), key="api_selector")
    genai.configure(api_key=API_KEYS[st.session_state.selected_api_key])
    
    with st.expander("æ–‡ä»¶æ“ä½œ"):
        if len(st.session_state.messages) > 0: st.button("é‡ç½®ä¸Šä¸€ä¸ªè¾“å‡º âª", on_click=lambda: st.session_state.messages.pop(-1))
        st.button("è¯»å–å†å²è®°å½• ğŸ“–", on_click=lambda: load_history(log_file))
        if st.button("æ¸…é™¤å†å²è®°å½• ğŸ—‘ï¸"): st.session_state.clear_confirmation = True
        if st.session_state.get("clear_confirmation"):
            c1, c2 = st.columns(2)
            if c1.button("ç¡®è®¤æ¸…é™¤", key="clear_confirm"): clear_history(log_file); st.session_state.clear_confirmation = False; st.experimental_rerun()
            if c2.button("å–æ¶ˆ", key="clear_cancel"): st.session_state.clear_confirmation = False; st.experimental_rerun()
        st.download_button("ä¸‹è½½å½“å‰èŠå¤©è®°å½• â¬‡ï¸", data=pickle.dumps(_prepare_messages_for_save(st.session_state.messages)), file_name=os.path.basename(log_file), mime="application/octet-stream")
        
        uploaded_pkl = st.file_uploader("è¯»å–æœ¬åœ°pklæ–‡ä»¶ ğŸ“", type=["pkl"], key="pkl_uploader")
        if uploaded_pkl is not None:
            try:
                st.session_state.messages = _reconstitute_messages_after_load(pickle.load(uploaded_pkl))
                st.success("æˆåŠŸè¯»å–æœ¬åœ°pklæ–‡ä»¶ï¼"); st.experimental_rerun()
            except Exception as e: st.error(f"è¯»å–æœ¬åœ°pklæ–‡ä»¶å¤±è´¥ï¼š{e}")

    with st.expander("å‘é€å›¾ç‰‡ä¸æ–‡å­—"):
        st.file_uploader("ä¸Šä¼ å›¾ç‰‡", type=["png", "jpg", "jpeg", "webp"], accept_multiple_files=True, key="sidebar_uploader", label_visibility="collapsed")
        st.text_area("è¾“å…¥æ–‡å­— (å¯é€‰)", key="sidebar_caption", height=100)
        st.button("å‘é€åˆ°å¯¹è¯ â†—ï¸", on_click=send_from_sidebar_callback, use_container_width=True)

    with st.expander("è§’è‰²è®¾å®š"):
        # ... (æ­¤éƒ¨åˆ†ä»£ç å®Œå…¨ä¸å˜)
        pass # Placeholder for brevity, the original code is fine

# --- åŠ è½½å’Œæ˜¾ç¤ºèŠå¤©è®°å½• (ä¿æŒä¸å˜) ---
if not st.session_state.messages and not st.session_state.is_generating: load_history(log_file)
for i, message in enumerate(st.session_state.messages):
    with st.chat_message(message["role"]):
        # ... (æ­¤éƒ¨åˆ†ä»£ç å®Œå…¨ä¸å˜)
        for part in message.get("content", []):
            if isinstance(part, str): st.markdown(part, unsafe_allow_html=True)
            elif isinstance(part, Image.Image): st.image(part, width=400)


# --- ç¼–è¾‘ç•Œé¢æ˜¾ç¤ºé€»è¾‘ (ä¿æŒä¸å˜) ---
if st.session_state.get("editing"):
    i = st.session_state.editable_index
    message = st.session_state.messages[i]
    with st.chat_message(message["role"]):
        current_text = message["content"][0] if message["content"] and isinstance(message["content"][0], str) else ""
        new_text = st.text_area(f"ç¼–è¾‘ {message['role']} çš„æ¶ˆæ¯:", current_text, key=f"edit_area_{i}")
        c1, c2 = st.columns(2)
        if c1.button("ä¿å­˜ âœ…", key=f"save_{i}"):
            st.session_state.messages[i]["content"][0] = new_text
            with open(log_file, "wb") as f: pickle.dump(_prepare_messages_for_save(st.session_state.messages), f)
            st.session_state.editing = False; st.experimental_rerun()
        if c2.button("å–æ¶ˆ âŒ", key=f"cancel_{i}"):
            st.session_state.editing = False; st.experimental_rerun()

# --- ç»­å†™/ç¼–è¾‘/é‡ç”ŸæˆæŒ‰é’®é€»è¾‘ (ä¿®æ”¹äº†â€œç»§ç»­â€æŒ‰é’®çš„å›è°ƒ) ---
if len(st.session_state.messages) >= 1 and not st.session_state.is_generating and not st.session_state.editing:
    last_idx = len(st.session_state.messages) - 1
    last_msg = st.session_state.messages[last_idx]
    is_text_only_assistant = (last_msg["role"] == "assistant" and len(last_msg.get("content", [])) == 1 and isinstance(last_msg["content"][0], str))
    
    if is_text_only_assistant:
        with st.container():
            cols = st.columns(20)
            if cols[0].button("âœï¸", key="edit", help="ç¼–è¾‘"): st.session_state.editable_index = last_idx; st.session_state.editing = True; st.experimental_rerun()
            if cols[1].button("â™»ï¸", key="regen", help="é‡æ–°ç”Ÿæˆ"): regenerate_message(last_idx)
            # â˜…â˜…â˜… ä¿®æ”¹äº†è¿™é‡Œçš„ on_click â˜…â˜…â˜…
            if cols[2].button("â•", key="cont", help="ç»§ç»­", on_click=start_continuation):
                pass # on_click handles the logic, no need for code here
    elif last_msg["role"] == "assistant":
         if st.columns(20)[0].button("â™»ï¸", key="regen_vision", help="é‡æ–°ç”Ÿæˆ"): regenerate_message(last_idx)

# --- æ ¸å¿ƒäº¤äº’é€»è¾‘ (ä¸»è¾“å…¥æ¡†, ä¿æŒä¸å˜) ---
if not st.session_state.is_generating:
    if prompt := st.chat_input("è¾“å…¥ä½ çš„æ¶ˆæ¯...", key="main_chat_input", disabled=st.session_state.editing):
        token = generate_token()
        full_prompt = f"{prompt} (token: {token})" if st.session_state.use_token else prompt
        st.session_state.messages.append({"role": "user", "content": [full_prompt]})
        st.session_state.is_generating = True
        st.experimental_rerun()

# --- æ ¸å¿ƒç”Ÿæˆé€»è¾‘ (å·²å®ç°è‡ªåŠ¨ç»­å†™) ---
if st.session_state.is_generating:
    with st.chat_message("assistant"):
        placeholder = st.empty()
        # ç¡®ä¿æˆ‘ä»¬æœ‰ä¸€ä¸ª assistant æ¶ˆæ¯å¯ä»¥å†™å…¥
        if not st.session_state.messages or st.session_state.messages[-1]["role"] != "assistant":
            st.session_state.messages.append({"role": "assistant", "content": [""]})

        full_response = ""
        try:
            # æ­£å¸¸æµå¼ç”Ÿæˆ
            for chunk in getAnswer():
                full_response += chunk
                st.session_state.messages[-1]["content"][0] = full_response
                placeholder.markdown(full_response + "â–Œ")
            # æˆåŠŸç”Ÿæˆï¼Œæ˜¾ç¤ºæœ€ç»ˆç»“æœ
            placeholder.markdown(full_response)

        except Exception as e:
            # â˜…â˜…â˜… å…³é”®ä¿®å¤ï¼šå®ç°è‡ªåŠ¨ç»­å†™é€»è¾‘ â˜…â˜…â˜…
            # æ•è·åˆ°ä¸­æ–­å¼‚å¸¸ (å¦‚ Gemini çš„ BlockedPromptException)
            st.warning(f"å›ç­”æµè¢«ä¸­æ–­ ({type(e).__name__})ï¼Œæ­£åœ¨å°è¯•è‡ªåŠ¨ç»§ç»­ç”Ÿæˆ...")
            placeholder.markdown(full_response + " ğŸ”„") # æç¤ºç”¨æˆ·æ­£åœ¨ç»­å†™

            try:
                # 1. å‡†å¤‡ç»­å†™æ‰€éœ€çš„å†å²è®°å½•å’Œæç¤º
                # å†å²è®°å½•å°±æ˜¯å½“å‰ st.session_state.messages çš„å†…å®¹ï¼Œå› ä¸ºå®ƒå·²ç»åŒ…å«äº†éƒ¨åˆ†å›ç­”
                temp_history = [{"role": ("model" if m["role"] == "assistant" else "user"), "parts": m["content"]} for m in st.session_state.messages]
                
                # æ„é€ ç»­å†™æç¤º
                last_chars = (full_response[-50:] + "...") if len(full_response) > 50 else full_response
                continue_prompt = f"è¯·ä¸¥æ ¼åœ°ã€æ— ç¼åœ°ä»ä¸‹é¢çš„æ–‡æœ¬ç‰‡æ®µæœ«å°¾ç»§ç»­å†™ï¼Œä¸è¦é‡å¤ä»»ä½•å†…å®¹ï¼Œä¸è¦æ·»åŠ ä»»ä½•å¼•è¨€æˆ–è§£é‡Šï¼Œç›´æ¥è¾“å‡ºåç»­çš„æ–‡æœ¬ï¼š\n'{last_chars}'"
                temp_history.append({"role": "user", "parts": [continue_prompt]})

                # 2. è°ƒç”¨APIè¿›è¡Œç»­å†™ (éæµå¼)
                continue_response_obj = model.generate_content(temp_history)
                continued_text = continue_response_obj.text

                # 3. å°†ç»­å†™çš„å†…å®¹è¿½åŠ åˆ°åŸå§‹éƒ¨åˆ†åé¢
                full_response += continued_text
                st.session_state.messages[-1]["content"][0] = full_response
                placeholder.markdown(full_response) # æ˜¾ç¤ºå®Œæ•´çš„æœ€ç»ˆç»“æœ
                st.success("è‡ªåŠ¨ç»­å†™æˆåŠŸï¼")

            except Exception as e2:
                # å¦‚æœè‡ªåŠ¨ç»­å†™ä¹Ÿå¤±è´¥äº†ï¼Œå°±æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯å¹¶æ”¾å¼ƒ
                err_msg = f"**å›ç­”ç”Ÿæˆä¸­æ–­ï¼Œè‡ªåŠ¨ç»­å†™ä¹Ÿå¤±è´¥äº†**: {type(e2).__name__}ã€‚è¯·æ‰‹åŠ¨å°è¯•ã€ç»§ç»­ã€‘æˆ–ã€é‡æ–°ç”Ÿæˆã€‘ã€‚"
                st.error(err_msg)
                # ä¿æŒæ˜¾ç¤ºä¸­æ–­å‰çš„éƒ¨åˆ†å†…å®¹
                placeholder.markdown(full_response)

        finally:
            # ç¡®ä¿ç©ºæ¶ˆæ¯ä¸è¢«ä¿å­˜
            if st.session_state.messages and st.session_state.messages[-1]['content'] and not st.session_state.messages[-1]["content"][0].strip():
                st.session_state.messages.pop()
            # æ— è®ºå¦‚ä½•ï¼Œéƒ½ä¿å­˜æœ€ç»ˆçš„èŠå¤©è®°å½•
            with open(log_file, "wb") as f:
                pickle.dump(_prepare_messages_for_save(st.session_state.messages), f)
            # ç»“æŸç”ŸæˆçŠ¶æ€å¹¶åˆ·æ–°
            st.session_state.is_generating = False
            st.experimental_rerun()


# --- åº•éƒ¨æ§ä»¶ (ä¿æŒä¸å˜) ---
c1, c2 = st.columns(2)
st.session_state.use_token = c1.checkbox("ä½¿ç”¨ Token", value=st.session_state.get("use_token", True))
if c2.button("ğŸ”„", key="page_refresh", help="åˆ·æ–°é¡µé¢"): st.experimental_rerun()
