import os
import google.generativeai as genai
import streamlit as st
import pickle
import random
import string
from io import BytesIO
import zipfile

# --- Streamlit Page Configuration ---
st.set_page_config(
    page_title="Gemini Chatbot",
    layout="wide"
)

# --- API å¯†é’¥è®¾ç½® (ä¿æŒåŸæ ·) ---
API_KEYS = {
    "ä¸»å¯†é’¥": "AIzaSyCBjZbA78bPusYmUNvfsmHpt6rPx6Ur0QE",
    "å¤‡ç”¨1å·": "AIzaSyAWfFf6zqy1DizINOwPfxPD8EF2ACdwCaQ",
    "å¤‡ç”¨2å·":"AIzaSyD4UdMp5wndOAKxtO1CWpzuZEGEf78YKUQ",
    "å¤‡ç”¨3å·":"AIzaSyBVbA7tEyyy_ASp7l9P60qSh1xOM2CSMNw",
    "å¤‡ç”¨4å·":"AIzaSyDezEpxvtY1AKN6JACMU9XHte5sxATNcUs",
    "å¤‡ç”¨5å·":"AIzaSyBgyyy2kTTAdsLB53OCR2omEbj7zlx1mjw",
    "å¤‡ç”¨6å·":"AIzaSyDPFZ7gRba9mhKTqbXA_Y7fhAxS8IEu0bY",
    "å¤‡ç”¨7å·":"AIzaSyDdyhqcowl0ftcbK9pMObXzM7cIOQMtlmA",
    "å¤‡ç”¨8å·":"AIzaSyAA7Qs9Lzy4UxxIqCIQ4RknchiWQt_1hgI",
    "å¤‡ç”¨9å·":"AIzaSyCj_CCwQua1mfq3EjzqV6Up6NHsxtb9dy8",
    "å¤‡ç”¨10å·":"AIzaSyDOI2e-I1RdXBnk99jY2H00A3aymXREETA"
}

# --- åˆå§‹åŒ– Session State ---
if "selected_api_key" not in st.session_state:
    st.session_state.selected_api_key = list(API_KEYS.keys())[0]
if "messages" not in st.session_state:
    st.session_state.messages = []
if 'character_settings' not in st.session_state:
    st.session_state.character_settings = {}
if 'enabled_settings' not in st.session_state:
    st.session_state.enabled_settings = {}
if 'regenerate_index' not in st.session_state:
    st.session_state.regenerate_index = None
if 'continue_index' not in st.session_state:
    st.session_state.continue_index = None
if "reset_history" not in st.session_state:
    st.session_state.reset_history = False
if "chat_session" not in st.session_state:
    st.session_state.chat_session = None
if "rerun_count" not in st.session_state:
    st.session_state.rerun_count = 0
if "use_token" not in st.session_state:
    st.session_state.use_token = True
# â˜…â˜…â˜… æ–°å¢/ä¿®æ”¹ï¼šçŠ¶æ€é”åˆå§‹åŒ– â˜…â˜…â˜…
if "is_generating" not in st.session_state:
    st.session_state.is_generating = False
if "error_occurred" not in st.session_state:
    st.session_state.error_occurred = False # æ–°å¢é”™è¯¯çŠ¶æ€æ ‡å¿—

# --- é…ç½® API å¯†é’¥ (ä¿æŒåŸæ ·) ---
genai.configure(api_key=API_KEYS[st.session_state.selected_api_key])

# --- æ¨¡å‹è®¾ç½® (ä¿æŒåŸæ ·) ---
generation_config = {
  "temperature": 1.6, "top_p": 0.95, "top_k": 40, "max_output_tokens": 8192, "response_mime_type": "text/plain",
}
safety_settings = [
    {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
]
model = genai.GenerativeModel(
  model_name="gemini-2.5-flash-preview-05-20",
  generation_config=generation_config,
  safety_settings=safety_settings,
  system_instruction="""
{
    "prompts": [
        {
            "name": "ğŸ’®äºŒé€‰ä¸€ğŸ’®å¼ºåŒ–èº«ä»½å®šä¹‰â€”å°è¯´ä¹‹å¼Ÿ", "system_prompt": true, "role": "system",
            "content": "<Writer_Activation>...</Writer_Activation>", # å†…å®¹ä¿æŒä¸å˜ï¼Œæ­¤å¤„çœç•¥
            "identifier": "main", "forbid_overrides": true, "injection_position": 0, "injection_depth": 4
        }
    ]
}
""",
)

# --- é»˜è®¤è§’è‰²è®¾å®š (ä¿æŒåŸæ ·) ---
DEFAULT_CHARACTER_SETTINGS = {"ç†å¤–ç¥ç¦": """ã€ç†å¤–ç¥ç¦ã€‘çš„æ ¸å¿ƒæ¦‚å¿µï¼š\n\n"""}

# --- æ–‡ä»¶æ“ä½œå‡½æ•° (ä¿æŒåŸæ ·) ---
file = os.path.abspath(__file__)
filename = os.path.splitext(os.path.basename(file))[0] + ".pkl"
log_file = os.path.join(os.path.dirname(file), filename)
if not os.path.exists(log_file):
    with open(log_file, "wb") as f: pass

# --- åŠŸèƒ½å‡½æ•° (æ‰€æœ‰åŠŸèƒ½å‡½æ•°ä¿æŒåŸæ ·) ---
def generate_token():
    # ... (ä»£ç ä¸å˜)
    import random
    import string
    random.seed()
    token_length = random.randint(10, 15)
    characters = "ä¸€ä¹™äºŒåä¸å‚ä¸ƒåœäººå…¥å…«ä¹å‡ å„¿äº†åŠ›ä¹ƒåˆ€åˆä¸‰äºå¹²äºå£«å·¥åœŸæ‰å¯¸ä¸‹å¤§ä¸ˆä¸ä¸‡ä¸Šå°å£å·¾å±±åƒä¹å·äº¿ä¸ªå‹ºä¹…å‡¡åŠå¤•ä¸¸ä¹ˆå¹¿äº¡é—¨ä¹‰ä¹‹å°¸å¼“å·±å·²å­å«ä¹Ÿå¥³é£åˆƒä¹ å‰é©¬ä¹¡ä¸°ç‹äº•"
    hanzi_token = "".join(random.choice(characters) for _ in range(token_length - 1))
    probability = random.random()
    if probability < 0.4: digit_count = 1
    elif probability < 0.7: digit_count = 2
    else: digit_count = 3
    digit_token = "ã€".join(random.choice(string.digits) for _ in range(digit_count))
    return f"({hanzi_token})({digit_token})"

def load_history(log_file):
    # ... (ä»£ç ä¸å˜)
    try:
        with open(log_file, "rb") as f: st.session_state.messages = pickle.load(f)
        st.success(f"æˆåŠŸè¯»å–å†å²è®°å½•ï¼({os.path.basename(log_file)})")
        st.session_state.chat_session = None
        st.session_state.rerun_count += 1
    except (FileNotFoundError, EOFError, Exception) as e:
        st.warning(f"è¯»å–å†å²è®°å½•å¤±è´¥: {e}")

def clear_history(log_file):
    # ... (ä»£ç ä¸å˜)
    st.session_state.messages.clear()
    st.session_state.chat_session = None
    if os.path.exists(log_file): os.remove(log_file)
    st.success("å†å²è®°å½•å·²æ¸…é™¤ï¼")

def ensure_enabled_settings_exists():
    # ... (ä»£ç ä¸å˜)
    for setting_name in st.session_state.character_settings:
        if setting_name not in st.session_state.enabled_settings:
            st.session_state.enabled_settings[setting_name] = False
ensure_enabled_settings_exists()

def getAnswer(prompt):
    # ... (å¤§éƒ¨åˆ†ä»£ç ä¸å˜, çœç•¥å†…éƒ¨æ„é€ )
    prompt = prompt or ""
    history_messages = []
    # ... æ„å»º history_messages çš„é€»è¾‘ä¿æŒä¸å˜ ...
    for msg in st.session_state.messages[-20:]:
        if msg and msg.get("role") and msg.get("content"):
            if msg["role"] == "user": history_messages.append({"role": "user", "parts": [{"text": msg["content"]}]})
            elif msg["role"] == "assistant" and msg["content"] is not None: history_messages.append({"role": "model", "parts": [{"text": msg["content"]}]})
    if prompt:
        history_messages.append({"role": "user", "parts": [{"text": prompt}]})
    response = model.generate_content(contents=history_messages, stream=True)
    yield from response

def regenerate_message(index):
    # ... (ä»£ç ä¸å˜)
    if 0 <= index < len(st.session_state.messages):
        st.session_state.messages = st.session_state.messages[:index]
        new_prompt = "è¯·é‡æ–°å†™"
        st.session_state.messages.append({"role": "user", "content": new_prompt})
        st.session_state.is_generating = True
        st.experimental_rerun()
    else:
        st.error("æ— æ•ˆçš„æ¶ˆæ¯ç´¢å¼•")

def continue_message(index):
    # ... (ä»£ç ä¸å˜)
    if 0 <= index < len(st.session_state.messages):
        message_to_continue = st.session_state.messages[index]
        original_message_content = message_to_continue["content"]
        # ... (åç»­æ‹¼æ¥å’Œæµå¼æ›´æ–°é€»è¾‘ä¿æŒä¸å˜) ...
        # æ­¤å¤„çœç•¥ï¼Œä»¥ä¿æŒç®€æ´
        # ä½†å®ƒçš„æ ¸å¿ƒé€»è¾‘è¢«ä¸‹é¢çš„â€œé”™è¯¯æ¢å¤â€éƒ¨åˆ†å€Ÿé‰´äº†
    else:
        st.error("æ— æ•ˆçš„æ¶ˆæ¯ç´¢å¼•")

# --- UI ç•Œé¢éƒ¨åˆ† (ä¿æŒåŸæ ·) ---
with st.sidebar:
    # ... (æ‰€æœ‰ä¾§è¾¹æ ä»£ç ä¿æŒä¸å˜ï¼Œæ­¤å¤„çœç•¥) ...
    st.session_state.selected_api_key = st.selectbox("é€‰æ‹© API Key:", options=list(API_KEYS.keys()), index=list(API_KEYS.keys()).index(st.session_state.selected_api_key), key="api_selector")
    genai.configure(api_key=API_KEYS[st.session_state.selected_api_key])
    with st.expander("æ–‡ä»¶æ“ä½œ"): pass # çœç•¥å†…éƒ¨
    with st.expander("è§’è‰²è®¾å®š"): pass # çœç•¥å†…éƒ¨

# è‡ªåŠ¨åŠ è½½å†å²è®°å½•
if not st.session_state.messages and not st.session_state.is_generating and not st.session_state.error_occurred:
    load_history(log_file)

# æ˜¾ç¤ºå†å²è®°å½•å’Œç¼–è¾‘åŠŸèƒ½ (ä¿æŒåŸæ ·)
for i, message in enumerate(st.session_state.messages):
    with st.chat_message(message["role"]):
        message_placeholder = st.empty()
        message_placeholder.write(message["content"], key=f"message_{i}")
        st.session_state.messages[i]["placeholder_widget"] = message_placeholder

if st.session_state.get("editing"):
    # ... (ç¼–è¾‘é€»è¾‘ä¿æŒä¸å˜ï¼Œæ­¤å¤„çœç•¥) ...
    pass

# æœ€åä¸€æ¡æ¶ˆæ¯ä¸‹æ–¹çš„ç´§å‡‘å›¾æ ‡æŒ‰é’® (ä¿æŒåŸæ ·)
if len(st.session_state.messages) >= 1 and not st.session_state.is_generating and not st.session_state.error_occurred:
    # ... (ç¼–è¾‘/é‡ç”Ÿæˆ/ç»§ç»­æŒ‰é’®é€»è¾‘ä¿æŒä¸å˜ï¼Œæ­¤å¤„çœç•¥) ...
    pass

# â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…
# â˜…â˜…â˜…        æ ¸å¿ƒäº¤äº’é€»è¾‘ - ä½¿ç”¨ä¸‰æ®µå¼çŠ¶æ€æœºï¼ˆè¾“å…¥/ç”Ÿæˆ/é”™è¯¯ï¼‰        â˜…â˜…â˜…
# â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…

# çŠ¶æ€ä¸‰ï¼šé”™è¯¯æ¢å¤æ¨¡å¼
if st.session_state.get("error_occurred"):
    st.warning("ç”Ÿæˆè¢«ä¸­æ–­ã€‚æ‚¨å¯ä»¥é€‰æ‹©ç»§ç»­ç”Ÿæˆã€‚")
    if st.button("ç»§ç»­ç”Ÿæˆ ...", key="continue_from_error"):
        # è¿›å…¥è¿™ä¸ªå—æ„å‘³ç€ç”¨æˆ·ç‚¹å‡»äº†æŒ‰é’®ï¼Œæˆ‘ä»¬è¦å¼€å§‹æ¢å¤æ€§ç”Ÿæˆ
        last_message = st.session_state.messages[-1]
        original_content = last_message["content"]
        placeholder = last_message.get("placeholder_widget")

        with st.spinner("æ­£åœ¨å°è¯•ç»§ç»­ç”Ÿæˆ..."):
            try:
                # æ„é€ ç»­å†™æç¤º
                last_chars_length = 20
                last_chars = original_content[-last_chars_length:] if len(original_content) > last_chars_length else original_content
                continue_prompt = f"è¯·åŠ¡å¿…ä» '{last_chars}' æ— ç¼è¡”æ¥è‡ªç„¶åœ°ç»§ç»­å†™ï¼Œä¸è¦é‡å¤ï¼Œä¸è¦è¾“å‡ºä»»ä½•æ€è€ƒè¿‡ç¨‹æˆ–é“æ­‰ã€‚"

                # å¼€å§‹æµå¼ç»­å†™
                continued_response = ""
                response_stream = getAnswer(continue_prompt)
                for chunk in response_stream:
                    continued_response += chunk.text
                    updated_content = original_content + continued_response
                    if placeholder:
                        placeholder.markdown(updated_content + "â–Œ")
                    st.session_state.messages[-1]["content"] = updated_content

                # æˆåŠŸç»­å†™ï¼Œé‡ç½®çŠ¶æ€
                st.session_state.error_occurred = False

            except Exception as e:
                # å¦‚æœç»­å†™å†æ¬¡å¤±è´¥ï¼Œåœç•™åœ¨é”™è¯¯çŠ¶æ€ï¼Œè®©ç”¨æˆ·å¯ä»¥å†æ¬¡å°è¯•
                st.error(f"ç»§ç»­ç”Ÿæˆæ—¶å†æ¬¡å‘ç”Ÿé”™è¯¯: {type(e).__name__} - {e}")
                # ä¸éœ€è¦æ”¹å˜çŠ¶æ€ï¼ŒUIä¼šåˆ·æ–°ï¼ŒæŒ‰é’®ä¾ç„¶å¯è§

            finally:
                # æ— è®ºç»­å†™æ˜¯å¦æˆåŠŸï¼Œéƒ½ä¿å­˜å½“å‰è®°å½•
                with open(log_file, "wb") as f:
                    messages_to_pickle = [msg.copy() for msg in st.session_state.messages]
                    for msg in messages_to_pickle:
                        msg.pop("placeholder_widget", None)
                    pickle.dump(messages_to_pickle, f)
                
                # è§¦å‘åˆ·æ–°æ¥æ›´æ–°UIçŠ¶æ€
                st.experimental_rerun()


# çŠ¶æ€äºŒï¼šæ­£åœ¨ç”Ÿæˆæ¨¡å¼
elif st.session_state.is_generating:
    last_user_prompt = st.session_state.messages[-2]["content"] # è·å–çœŸæ­£çš„ç”¨æˆ·è¾“å…¥
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        st.session_state.messages[-1]["placeholder_widget"] = message_placeholder
        full_response = ""
        try:
            response_stream = getAnswer(last_user_prompt)
            for chunk in response_stream:
                full_response += chunk.text
                message_placeholder.markdown(full_response + "â–Œ")
                st.session_state.messages[-1]["content"] = full_response
            message_placeholder.markdown(full_response)
            st.session_state.is_generating = False # æ­£å¸¸ç»“æŸï¼Œè§£é™¤ç”Ÿæˆé”å®š

        except Exception as e:
            # â˜…â˜…â˜… å…³é”®æ”¹åŠ¨ï¼šå‘ç”Ÿé”™è¯¯æ—¶ï¼Œä¸ç»“æŸæµç¨‹ï¼Œè€Œæ˜¯è½¬æ¢åˆ°â€œé”™è¯¯æ¢å¤â€çŠ¶æ€ â˜…â˜…â˜…
            st.session_state.is_generating = False
            st.session_state.error_occurred = True
            st.error(f"ç”Ÿæˆè¢«ä¸­æ–­: {type(e).__name__} - {e}ã€‚éƒ¨åˆ†å›å¤å·²ä¿å­˜ã€‚")

        finally:
            # æ— è®ºå¦‚ä½•éƒ½ä¿å­˜ä¸€æ¬¡æ–‡ä»¶
            with open(log_file, "wb") as f:
                messages_to_pickle = [msg.copy() for msg in st.session_state.messages]
                for msg in messages_to_pickle:
                    msg.pop("placeholder_widget", None)
                pickle.dump(messages_to_pickle, f)
            # åˆ·æ–°ä»¥æ ¹æ®æ–°çŠ¶æ€ï¼ˆis_generating=False, error_occurred=True/Falseï¼‰æ›´æ–°UI
            st.experimental_rerun()

# çŠ¶æ€ä¸€ï¼šç­‰å¾…è¾“å…¥æ¨¡å¼ (é»˜è®¤)
else:
    if prompt := st.chat_input("è¾“å…¥ä½ çš„æ¶ˆæ¯:", key="main_chat_input"):
        token = generate_token()
        full_prompt = f"{prompt} (token: {token})" if st.session_state.use_token else prompt
        
        # æ˜¾ç¤ºå¹¶ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
        with st.chat_message("user"):
            st.markdown(full_prompt)
        st.session_state.messages.append({"role": "user", "content": full_prompt})
        # ä¸ºAIçš„å›å¤é¢„å…ˆå ä½
        st.session_state.messages.append({"role": "assistant", "content": ""})

        # é”å®šçŠ¶æ€å¹¶åˆ·æ–°ï¼Œè¿›å…¥â€œç”Ÿæˆä¸­â€æ¨¡å¼
        st.session_state.is_generating = True
        st.experimental_rerun()

# --- åº•éƒ¨æ§ä»¶ (ä¿æŒåŸæ ·) ---
col1, col2 = st.columns(2)
with col1:
    st.checkbox("ä½¿ç”¨ Token", value=st.session_state.use_token, key="token_checkbox_controller")
    st.session_state.use_token = st.session_state.token_checkbox_controller
with col2:
    if st.button("ğŸ”„", key="refresh_button"):
        st.experimental_rerun()
