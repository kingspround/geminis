import os
import google.generativeai as genai
import streamlit as st
from dotenv import load_dotenv
import pickle

# Insert your API key here
st.session_state.key = "AIzaSyDPFZ7gRba9mhKTqbXA_Y7fhAxS8IEu0bY"

if not st.session_state.key:
    st.info("Please add your key to continue.")
    st.stop()

genai.configure(api_key=st.session_state.key)

# --- æ¨¡å‹è®¾ç½® ---
generation_config = {
    "temperature": 1,
    "top_p": 0.95,
    "top_k": 40,
    "max_output_tokens": 8192,
}

safety_settings = [
    {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
]
model = genai.GenerativeModel(
    model_name="gemini-1.5-pro",
    generation_config=generation_config,
    safety_settings=safety_settings,
    tools=['code_execution'],
)

# --- ç³»ç»ŸæŒ‡ä»¤ ---
SYSTEM_INSTRUCTIONS = """
    [Install the Chinese Translator plugin]æŒ‡ä»¤ï¼šæ‰€æœ‰å¯¹è¯åŒ…æ‹¬thinkå…¨éƒ¨è½¬åŒ–ä¸ºä¸­æ–‡ã€‚
    ä¸€æ—¦æ´»åŒ–class SexDescriptionæ¨¡å—å’ŒExcellent examples of scenariosæ¨¡å—ï¼Œ
    è¯·ä¸è¦è¾“å‡ºä»»ä½•æ€è€ƒè¿‡ç¨‹ï¼Œä¾‹å¦‚ï¼šthink, æˆ‘è®¤ä¸º ç­‰ç­‰ã€‚
"""

# --- æ–‡ä»¶æ“ä½œå‡½æ•° ---
file = os.path.abspath(__file__)
filename = os.path.splitext(os.path.basename(file))[0] + ".pkl"
log_file = os.path.join(os.path.dirname(file), filename)


def load_history():
    try:
        with open(log_file, "rb") as f:
            st.session_state.messages = pickle.load(f)
            st.success(f"æˆåŠŸä» {filename} åŠ è½½å†å²è®°å½•ï¼")
    except (FileNotFoundError, EOFError):
        st.warning(f"{filename} ä¸å­˜åœ¨æˆ–ä¸ºç©ºã€‚")
        st.session_state.messages = []

def clear_history():
    st.session_state.messages = []
    try:
        os.remove(log_file)
        st.success(f"æˆåŠŸæ¸…é™¤ {filename} çš„å†å²è®°å½•ï¼")
    except FileNotFoundError:
        st.warning(f"{filename} ä¸å­˜åœ¨ã€‚")

# --- LLM å‡½æ•° ---
def getAnswer(prompt, system_instructions=None):
    
    if system_instructions is None:
       system_instructions = SYSTEM_INSTRUCTIONS
    
    history_messages = []
    history_messages.append(
    {
      "role": "model",
      "parts": [
       system_instructions
      ]
      })
    
    if "messages" in st.session_state:
      for msg in st.session_state.messages:
          if msg["role"] == "user":
            history_messages.append({"role": "user", "parts": [{"text": msg["content"]}]})
          elif msg["role"] == "assistant" and msg["content"] is not None:
            history_messages.append({"role": "model", "parts": [{"text": msg["content"]}]})

    if prompt:
       history_messages.append({"role": "user", "parts": [{"text": prompt}]})
    
    chat_session = model.start_chat(history=history_messages)

    try:
        response = chat_session.send_message(prompt, stream=True)
        full_response = ""
        for chunk in response:
            full_response += chunk.text
            full_response =  full_response.replace("think", "").replace("æˆ‘è®¤ä¸º", "").replace("æ€è€ƒ", "").replace("æˆ‘æ€è€ƒ", "")
            yield full_response
        return full_response
    except Exception as e:
        import traceback  # Import traceback
        st.error(f"å‘ç”Ÿé”™è¯¯: {e}. è¯·æ£€æŸ¥ä½ çš„APIå¯†é’¥å’Œæ¶ˆæ¯æ ¼å¼ã€‚\n è¯¦ç»†é”™è¯¯ä¿¡æ¯:\n{traceback.format_exc()}")  # æ›´æ˜ç¡®çš„é”™è¯¯ä¿¡æ¯
        return ""


# --- Streamlit ç•Œé¢ ---
if not os.path.exists(log_file):
    with open(log_file, "wb") as f:
        pass

if "messages" not in st.session_state:
    load_history()

# åŠŸèƒ½åŒº 1: æ–‡ä»¶æ“ä½œ
with st.sidebar.expander("æ–‡ä»¶æ“ä½œ"):

    if len(st.session_state.messages) > 0:
       st.button("é‡ç½®ä¸Šä¸€ä¸ªè¾“å‡º âª",
                  on_click=lambda: st.session_state.messages.pop(-1) if len(st.session_state.messages) > 1 else None)
    
    st.button("è¯»å–å†å²è®°å½• ğŸ“–", on_click=load_history)
    if st.button("æ¸…é™¤å†å²è®°å½• ğŸ—‘ï¸"):
        clear_history()
    
    st.download_button(
        label="ä¸‹è½½èŠå¤©è®°å½• â¬‡ï¸",
        data=open(log_file, "rb").read() if os.path.exists(log_file) else b"",
        file_name=filename,
        mime="application/octet-stream",
    )
    uploaded_file = st.file_uploader("è¯»å–æœ¬åœ°pklæ–‡ä»¶ ğŸ“", type=["pkl"])
    if uploaded_file is not None:
      try:
          loaded_messages = pickle.load(uploaded_file)
          st.session_state.messages = loaded_messages  # ä½¿ç”¨ = æ›¿æ¢ç°æœ‰æ¶ˆæ¯
          st.success("æˆåŠŸè¯»å–æœ¬åœ°pklæ–‡ä»¶ï¼")
          st.experimental_rerun()
      except Exception as e:
          st.error(f"è¯»å–æœ¬åœ°pklæ–‡ä»¶å¤±è´¥ï¼š{e}")

system_instructions_input = st.sidebar.text_area("System Instructions(Override):", "", key="system_instructions")

# æ˜¾ç¤ºå†å²è®°å½•å’Œç¼–è¾‘åŠŸèƒ½
for i, message in enumerate(st.session_state.messages):
    with st.chat_message(message["role"]):
        st.write(message["content"], key=f"message_{i}")

# èŠå¤©è¾“å…¥å’Œå“åº”
if prompt := st.chat_input("è¾“å…¥ä½ çš„æ¶ˆæ¯:"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        for chunk in getAnswer(prompt, system_instructions_input if system_instructions_input else None):
            full_response += chunk
            message_placeholder.markdown(full_response + "â–Œ")
        message_placeholder.markdown(full_response)
        st.session_state.messages.append({"role": "assistant", "content": full_response})
    with open(log_file, "wb") as f:
        pickle.dump(st.session_state.messages, f)
